# <div style="text-align: right"> February 18, 2020</div>
### Agenda:
- 
### Homework:
- 
---
## I. Logistic Regression (cont'd)
- Statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extension exist.
- In regression analysis, logistic regression (or logit regession) is estimating the parameters of a logistic model (a form of binary regression)
- We will look at two more models that are commonly used for classification tasks:
    - Logistic Regression and Softmax Regression
- Logistic Regression:
    - More generally, a linear model makes a prediction by simply computing a weighted sum of the input features, plus a constant called the `bias term` (also called the `intercept term`)
    - How do we train it?
        - Well, recall that training a model means setting its parameters so that the model best fits the taining set.
        - FOr this purpose, we first need a measure of how well (or poorly) the model fits the training data.
        - In `Chapter 2` we saw that the most common performance measure of a regression model is the `Root Mean Square Error` (RMSE) (Equation 2-1).
        - Therefore, to train a Linear Regression model, you need to find the value of `Theta` that minimizes the RMSE.
        - In practice, it is simpler to minimize the `Mean Square Error` (MSE) than the RMSE, and it leads to the same result (because the value that minimizes a function also minimizes it square root).
- Computational Complexity:
    - The Normal Equation computs the inverse of `X^T * X`, which is an `n x n` matrix (where `n` is the number of features). 
    - The Computational Complexity of inverting such a matrix is typically about O(n^2.4) to O(n^3) depending on the implementation). In other words, if you double the number of features, you multiply the computation time by roughly 2^2.4 = 5.3 to 2^3 = 8
        - The Normal Equation gets very slow when the number of features grows lare (e.g., 100,000)
- Convergence Rate:
    - When the cost function is convex and its slope does not change abruptly (as is the case for MSE cost function), it can be shown that `Batch Gradient Descent` with a fixed learning rate has a convergence rate of O(1/iterations).
    - In other words, if you divide the tolerance e by 10 (to have a more precise solution), then the algorithm will have to run about 10 times more iterations.
- Stochastic Gradient Descent:
    - Picks random instance in the training set at every step and computes the gradients based only on that single instance.
    - Due to its stochastic (i.e., random) nature, this algorithm is much less regular than `Batch Gradient Descent`
        - Instead of gently decreasing until it reaches the minimum, the cost function will bounce up and down, decrasing only on average.
        - Over time it will end up very close to the minimum, but once it gets there it will continue to bounce around, never settling down.
        - So once the algorithm stops, the final parameter values are good, but not optimal. 
    - However, Stochastic Gradient Descent has a better chance of finding the global minimum than Batch Gradient Descent does.
- Polynomial Regression:
    - What if your data is actually more complex than a simple straight line?
        - You can actually use a linear model to fit a nonlinear data.
        - A simple way to do this is to add powers of each feature as new features, then train a linear model on this extended set of features.
        - This technique is called `Polynomal Regression`.
    - High-degree Polynomal Regression model is severely overfitting the training data, while the linear model is underfitting it.
    - The Model thw will generalize best in this case is the quadratic model.
        - It makes sense since the data was generated using a quadratic model, but in general you won't know what function generated the data, so how can you decide how complex your model should be?
        - How can you tell that your model is overfitting or underfitting the data?
            1. Use Cross-Validation:
                - Get an estimate of a model's generalization performance.
                - If a model performs well on the training data but generalizes poorly according to the cross-validation metrics, then your model is overfitting.
                - If it performs poorly on both, then it is underfitting.
                - This is one way to tell when a model is too simple or too complex
            2. Learning Curves:
                - These are plots of the model's performance on the training set and the validation set as a function of the training set size.
                - To generate the plots simply train the model several times on different sized subsets of the training set.
                - These Learning curves are typical of a underfitting model.
                - Both curves have reached a plateau; they are close and fairly high.
        - The Error on the training data is much lower than with the Linear Regression Model.
        - There is a gap between the Curves. This means the model performs significantly better o nthe training data than on the validation data, which is the hallmark of an overfitting model.
            - However, if you used a much larger training set, the two curves would continue to get closer.
---
## II. The Bias/Variance Tradeoff:
- An important theoretical result of statistics and Machine Learning is the fact that a model's generalization error can be expressed a the sum of three very different errors:
    - Bias:
        - This part of the generalization error is due to wrong assumptions, such as assuming that the data is linear when it is actually quadratic. A high-bias model is most likely to underfit the training data.
    - Variance:
        - This part is due to the model's excessive sensitivity to small variations in the training data.
        - A model with many degrees of freedom (such a high-degree polynomial model) is likely to have high variance, and thus to overfit the training data.
    - Irreducible Error:
        - This par is due to the noisiness of the data itself.
        - The only way to reduce this part of the error is to clean up the data.
        - Example:
            - Fix the data sources, such as broken sensors, or detect and remove outliers.
- Increasing a model's complexity will typically increase its variance and reduce its bias.
- Conversely, reducing a model's complexity incrases its bias and reduces its variance. This is why it is called a `tradeoff`.
---
## III. Regularized Linear Models:
- It is quite common for the cost function used during training to be different from the performace measure used for testing.
- Apart from regularization, another reason why they might be different is that a good training cost function should have optimization-friendly derivatives, while the performance measure used for testing should be as close as posible to the final objective.
- A good example of this is a classifier trained using a cost function such as the log loss but evaluated using precision/recall.
- Logistic Regression:
    - Is commonly used to estimate the probability that an instance belongs to a particular class.
        - What is the probability that this email is spam?
    - If the estimated probability is grater than 50%, then the model predicts that the instance belongs to the class (called the positive class, labeled '1'), or else it predicts that it does not (i.e., it belongs to the negative class, labeled '0').
    - This makes it a `Binary Classifier`
    - Estimating probabilities:
        - Computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the `logistic` of this result.
    - Training and Cost Function:
        - The objective of training is to set the parameter vector, theta, so that the model estimates high probabilities for positive instances (y = 1) and low probabilities for negative instances (y = 0). 
        - This idea is captured by the cost function for single training instance x.
        - The cost function over the whole training set is simply the average cost over all training instances.
    - Cross Entropy:
        - Corss Entropy originated from information theory.
        - Suppose you want to efficiently transmit information about the weather every day.
        - If there are eight options (sunny, rainy, etc.) you can encode each option using 3 bits since 2^3 = 8.
        - However, if you think it will be sunny almost every day, it would be much more efficient to code "sunny" on just one bit (0) and the other seven options on 4 bits (starting with a 1).
        - Corss Entropy measures the average number of bits you actually send per option.
        - If your assumption about the weather is perfect, cross entropy will just be equal to the entropy of the weather itself (i.e., its intrinsic unpredictability).
        - But if your assumptions are wrong (e.g., If it rains often), cross entropy will be greater by an amount called the `Kullback-Leibler Divergence`.
--- 

